const Hypercore = require('hypercore')
const reallyReady = require('hypercore-really-ready')
const ram = require('random-access-memory')
const hyperswarm = require('hyperswarm')
const compress = require('brotli').compress;
const decompress = require('brotli').decompress;
const intercept = require('intercept-hypercore-storage')

const through2 = require('through2')
const duplexify = require('duplexify')

module.exports = datdotservice

function datdotservice (opts) {

  { storagePath, profile } = opts

  const API = {
    // brotli w/ level 11 and using Mauve's module
    encode,
    // store encoded hypercore using Mauve's module and make host send extension message on every connection
    host,
    // connects to all peers in swarm until they find hoster (= the one who sends a specific extension message)
    attest,
    // using Mauve's module
    solveChallenge,
    // status messages for all these functions
    on,
  }
  return API

  /* --------------------------------------
                ENCODE
  ----------------------------------------- */
  function encode (request, cb) {
    const { feedkey, swarmkey, eid, hid } = request
    const feed = new Hypercore(ram, feedkey)
    const ehswarmkey = `datdot${chainid}:${eid}:${hid}`
    const efeed = new Hypercore(ram, ehswarmkey)

    feed.ready(() => {
      reallyReady(feed, (err) => {
        if (err) return console.log(err)
        efeed.ready(() => {
          reallyReady(efeed, (err) => {
            if (err) return console.log(err)
            const { hooks, ehooks } = makeHooks()
            intercept(feed, hooks)
            intercept(efeed, ehooks)
            replicate(feed, swarmkey)
            replicate(efeed, ehswarmkey)
            encodeTransfer(feed, efeed)
            efeed.rootHashes(efeed.length, (err, merkleRoot) => {
              cb(merkleRoot)
            })
          })
        })
      })
    })
}
// --------------------------------------------------------------------------
function makeHooks () {
  var wait1
  const array1 = []
  function noCapacity1 () { return false }

  function put1 (index, data, cb) { // receive chunk from publisher
    const slot = array1[index]
    if (slot) {
      slot(null, data)
      slot = undefined
    } else { slot = data }
    if (noCapacity1()) wait1 = cb
    else cb(null)
  }
  function get1 (index, cb) { // serve chunk to efeed
    const slot = array1[index]
    if (slot) {
      cb(null, slot)
      slot = undefined
      if (wait1 && !noCapacity1()) {
        wait1(null)
        wait1 = undefined
      }
    } else { slot = cb }
    cb(null, thedata)
  }

  var wait2
  const array2 = []
  const rootHashes2 = [] // merkle tree
  function noCapacity2 () { return false }
  function put2 (index, data, cb) { // receive chunk from feed
    const slot = array2[index]
    if (slot) {
      slot(null, data)
      slot = undefined
    } else { slot = data }
    if (noCapacity2()) wait2 = cb
    else cb(null)
  }
  function get2 (index, cb) { // serve chunk to hoster
    const slot = array2[index]
    if (slot) {
      cb(null, slot)
      slot = undefined
      if (wait2 && !noCapacity2()) {
        wait2(null)
        wait2 = undefined
      }
    } else { slot = cb }
    cb(null, thedata)
  }
  const hooks = { putData: put1, getData: get1 }
  const ehooks = { putData: put2, getData: get2 }
  return { hooks, ehooks }
}
// --------------------------------------------------------------------------
function encodeTransfer (feed, efeed) {
  const stream1 = feed.createReadStream()
  const stream2 = through2(compression)
  const stream3 = efeed.createWriteStream()
  stream1.pipe(stream2).pipe(stream3)
  function compression (chunk, enc, next) {
    var self = this
    const opts = {
      mode: 0, // 0 = generic, 1 = text, 2 = font (WOFF2)
      quality: 11, // 0 - 11
      lgwin: 22 // window size
    }
    self.push(compress(chunk, opts))
    next()
  }
}
/* --------------------------------------
              HOST
----------------------------------------- */
  function host (request, cb) {
    const { feedkey, swarmkey, eid, hid } = request
    const feed = new Hypercore(ram, feedkey)
    const ehswarmkey = `datdot${chainid}:${eid}:${hid}`
    const efeed = new Hypercore(storagePath, ehswarmkey)
    feed.ready(() => {
      reallyReady(feed, (err) => {
        if (err) return console.log(err)
        efeed.ready(() => {
          reallyReady(efeed, (err) => {
            if (err) return console.log(err)
            replicate(efeed, ehswarmkey)
            intercept(feed, { putData: () => {}, getData: makeGet })
            replicate(feed, swarmkey)
            efeed.rootHashes(efeed.length, (err, merkleRoot) => {
              cb(merkleRoot)
            })
          })
        })
      })
    })
  }

  // ---------------------------------------------------------------------
    function makeGet () {
      return (index, cb) => { // get chunk from encoded feed
        efeed.get(index, (err, chunk) => { cb(null, decompress(chunk)) })
      }
    }
  /* --------------------------------------
                ATTEST
  ----------------------------------------- */
  function attest () {}

  /* --------------------------------------
                SOLVE CHALLENGE
  ----------------------------------------- */
  function solveChallenge (challenge, cb) {}
    const { hosterID, planID, chunkIndexes} = challenge
    const chunkIndexes = []
    cb(merkleProof)
  /* --------------------------------------
                LISTEN TO EVENTS
  ----------------------------------------- */
  const listen = { on, off, once }
  function on (query, callback) {

  }
  function off (query, callback) {

  }
  function once (query, callback) {

  }
  // example usage
  // const handler = (err, data) => { }
  // listen.on(query, handler)
  // listen.off(query, handler)
  // listen.once(query, handler)

  /* --------------------------------------
                HELPERS
  ----------------------------------------- */

  function replicate (_feed, _swarmkey) {
    const swarm = hyperswarm()
    swarm.join(_swarmkey, { lookup: true, announce: true })
    swarm.on('connection', function (socket, info) {
      socket.pipe(_feed.replicate(info.client)).pipe(socket)
    })
  }

  // function encode (opts, proof, done) {
  //   if (!profile.verify(opts, proof)) throw new Error('verify signature!')
  //
  //   const { address } = opts
  //   const swarmE = hyperswarm()
  //   const feedE = hypercore() // @NOTE: use memory
  //   // @TODO: optimize, by not storing on disk, but forwarding directly
  //   const swarm = hyperswarm()
  //   const feed = hypercore(address) // @NOTE: use memory
  //   feed.on('ready', () => feedE.on('ready', () => {
  //     swarmE.join(hosterID, { announce: true })
  //     swarmE.on('connection', s => s.pipe(feedE.replicate(false)).pipe(s))
  //     swarm.join(feed.key, { lookup: true })
  //     swarm.on('connection', s => s.pipe(feed.replicate(true)).pipe(s))
  //
  //     // LESEZEICHEN:
  //     // @TODO: done('start syncing with hoster')
  //
  //
  //     feed.createReadStream().on('data', chunk => {
  //       compress(chunk, (err, chunkE) => feedE.append(chunkE))
  //     }).on('end', () => {
  //       // @TODO: notify the chain (done(encodedMerkleRoot))
  //       var merkleRootE = feedE.getMerkleRoot()
  //       done()
  //
  //       // LESEZEICHEN:
  //       // @TODO: done('commit to chain')
  //       // @TODO: done('listen for final done and end everything - cleanup')
  //
  //
  //       chainAPI.commit(myAccountId, event, merkleRootE)
  //     })
  //
  //   }))
  // }

  //
  // Helpers
  //
  // getData // from swarm
  // getChunk

}
